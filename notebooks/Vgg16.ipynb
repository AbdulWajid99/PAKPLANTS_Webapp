{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb803f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from re import sub\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56496ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a924bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator=train_datagen.flow_from_directory('output/train',\n",
    "                                                 target_size=IMG_SIZE,\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "\n",
    "val_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_generator=train_datagen.flow_from_directory('output/val',\n",
    "                                                     target_size=IMG_SIZE,\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77bc072",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_generator.class_indices\n",
    "class_list = list(classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907be9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0032f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE, weights='imagenet',include_top=False)\n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x)\n",
    "x=Dense(1024,activation='relu')(x)\n",
    "x=Dense(512,activation='relu')(x)\n",
    "preds=Dense(38,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e26cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de43ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfcca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      metrics.TruePositives(name='tp'),\n",
    "      metrics.FalsePositives(name='fp'),\n",
    "      metrics.TrueNegatives(name='tn'),\n",
    "      metrics.FalseNegatives(name='fn'), \n",
    "      metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      metrics.Precision(name='precision'),\n",
    "      metrics.Recall(name='recall'),\n",
    "      metrics.AUC(name='auc')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97e6056",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "model_history=model.fit(train_generator,\n",
    "                    validation_data =val_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97069e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model_history.history['accuracy']\n",
    "val_acc = model_history.history['val_accuracy']\n",
    "\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlim([0,9])\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "plt.savefig(\"model_Accuracy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0884da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915c37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba769041",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img('test/Basil.JPG',target_size=(224,224))\n",
    "x=image.img_to_array(img)\n",
    "x=x/255\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x=np.expand_dims(x,axis=0)\n",
    "\n",
    "\n",
    "a=np.argmax(model.predict(x), axis=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4e49e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
